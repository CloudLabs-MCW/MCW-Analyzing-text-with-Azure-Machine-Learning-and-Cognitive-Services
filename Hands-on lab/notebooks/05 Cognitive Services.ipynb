{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Pre-Built & Custom AI Services\n",
    "\n",
    "In this notebook, you will integrate with the Text Analytics API to augment the claims processing capabilities. In the end, you will integrate the API calls to the summarizer and classifier services that your deployed and produce a finished claim report that shows all of the processing applied to the claim text.\n",
    "\n",
    "The Text Analytics API is a cloud-based service that provides Natural Language Processing (NLP) features for text mining and text analysis. Here we will look at the following features from the API:\n",
    "\n",
    "- Sentiment Analysis\n",
    "- Opinion mining\n",
    "- Key phrase extraction\n",
    "- Language detection\n",
    "- PII detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup helper functions\n",
    "\n",
    "Run the cell below to enable helper functions to save locally the outputs as pickle files from the various Text Analytics services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "output_location = './cs_outputs'\n",
    "os.makedirs(output_location, exist_ok=True)\n",
    "\n",
    "def save_output(output, name):\n",
    "    file_name = os.path.join(output_location, name) + '.pkl'\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(output, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def get_output(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the following cell with the correct **endpoint URL** and **key** for your deployed instance of the Text Analytics API and run the cell. Be sure your `endpoint URL` value ends in a slash (/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = '...' #\"<your_text_analytics_api_endpoint>\"\n",
    "key = '...' #\"<your_text_analytics_key>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instantiate the Text Analytics Client**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "\n",
    "credential = AzureKeyCredential(key)\n",
    "client = TextAnalyticsClient(endpoint=endpoint, credential=credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup the example claims document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim = (\"I had called earlier to report a car accident and I spoke with Jane and she was very helpful. \"\n",
    "         \"However, the wait time on the call was unacceptable, I was on it for more than 30 minutes. \"\n",
    "         \"As requested, my license plate number is ABC2021. \"\n",
    "         \"Like I said on the phone, the accident was the other SUV fault \"\n",
    "         \"for making a sharp turn and hitting my car on the right passenger side. \"\n",
    "         \"Thankfully I was not hurt but the damage to the car is substantial. \"\n",
    "         \"I request you to process the claim urgently and give me a loner vehicle for the duration of repairs. \"\n",
    "         \"My mobile phone is 55-999-5555 if you need to reach me. Thank you.\")\n",
    "print(claim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "The Text Analytics API's Sentiment Analysis feature is used for detecting positive and negative sentiment. If you send a Sentiment Analysis request, the API will return sentiment labels (such as \"negative\", \"neutral\" and \"positive\") and confidence scores at the sentence and document-level.\n",
    "\n",
    "Run the cell below and observe the following:\n",
    "- Overall document level sentiment with breakdown of the sentiment scores\n",
    "- Sentence level sentiment with breakdown of the sentiment scores\n",
    "\n",
    "In the end we will save the raw response from the **analyze_sentiment** API in local directory: `output_location`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.analyze_sentiment(documents=[claim])[0]\n",
    "overall_sentiment = response.sentiment\n",
    "print(\"Document Sentiment: {}\".format(overall_sentiment))\n",
    "overall_positive_score = response.confidence_scores.positive\n",
    "overall_neutral_score = response.confidence_scores.neutral\n",
    "overall_negative_score = response.confidence_scores.negative\n",
    "print(\"Overall scores: positive={0:.2f}; neutral={1:.2f}; negative={2:.2f} \\n\".format\n",
    "      (overall_positive_score, overall_neutral_score, overall_negative_score))\n",
    "for idx, sentence in enumerate(response.sentences):\n",
    "    print(\"Sentence: {}\".format(sentence.text))\n",
    "    print(\"Sentiment: {}\".format(sentence.sentiment))\n",
    "    print(\"Sentence score: Positive={0:.2f} Neutral={1:.2f} Negative={2:.2f}\\n\".format\n",
    "          (sentence.confidence_scores.positive, \n",
    "           sentence.confidence_scores.neutral, \n",
    "           sentence.confidence_scores.negative\n",
    "          )\n",
    "         )\n",
    "save_output(response, 'sentiment_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opinion Mining\n",
    "\n",
    "You can also use the **analyze_sentiment** API to mine opinions in the document. Opinion Mining provides granular information about the opinions related to words in the text. \n",
    "\n",
    "Run the below cell and review the extracted opinions from claim document. Observe that the API detects the opinion expressed by the user regarding wait times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinions = []\n",
    "response = client.analyze_sentiment(documents=[claim], show_opinion_mining=True)[0]\n",
    "for sentence in response.sentences:\n",
    "    for mined_opinion in sentence.mined_opinions:\n",
    "        opinion = {}\n",
    "        opinion['Sentence'] = sentence.text\n",
    "        print(\"Sentence: {}\".format(sentence.text))\n",
    "        target = mined_opinion.target\n",
    "        opinion['target'] = target.text\n",
    "        opinion['target_sentiment'] = target.sentiment\n",
    "        print(\"Target: '{}' Sentiment: {} (scores: Positive={} Negative={})\".format(\n",
    "            target.text, \n",
    "            target.sentiment, \n",
    "            round(target.confidence_scores.positive, 1), \n",
    "            round(target.confidence_scores.negative, 1)))\n",
    "        opinion['assessments'] = []\n",
    "        for assessment in mined_opinion.assessments:\n",
    "            item = {}\n",
    "            item['assessment'] = assessment.text\n",
    "            item['assessment_sentiment'] = assessment.sentiment\n",
    "            opinion['assessments'].append(item)\n",
    "            print(\"Assessment: '{}' Sentiment: {} (scores: Positive={} Negative={}\".format(\n",
    "                assessment.text, \n",
    "                assessment.sentiment,\n",
    "                round(assessment.confidence_scores.positive, 1), \n",
    "                round(assessment.confidence_scores.negative, 1)))\n",
    "        print(\"\\n\")\n",
    "        opinions.append(opinion)\n",
    "save_output(response, 'opinion_mining_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Phrase Extraction\n",
    "\n",
    "The Key Phrase Extraction (KPE) capability of the Text Analytics API is useful to quickly identify the main points in a collection of documents. We will apply KPE to our claims text to extract main concepts in the text. Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_phrases = []\n",
    "try:\n",
    "    response = client.extract_key_phrases(documents = [claim])[0]\n",
    "    if not response.is_error:\n",
    "        print(\"\\tKey Phrases:\")\n",
    "        for phrase in response.key_phrases:\n",
    "            key_phrases.append(phrase)\n",
    "            print(\"\\t\\t\", phrase)\n",
    "        save_output(response, 'kpe_results')\n",
    "    else:\n",
    "        print(response.id, response.error)\n",
    "except Exception as err:\n",
    "    print(\"Encountered exception. {}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Detection\n",
    "\n",
    "The Language Detection feature of the Azure Text Analytics REST API evaluates text input for each document and returns language identifiers with a score that indicates the strength of the analysis.\n",
    "\n",
    "First, we will translate our claim to Spanish language and then evaluate the translated claim. Run the following two cells to detect the claims language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_spanish = (\"Había llamado antes para reportar un accidente automovilístico y hablé con Jane \"\n",
    "                 \"y ella fue de gran ayuda. Sin embargo, el tiempo de espera de la llamada fue inaceptable, \"\n",
    "                 \"estuve en ella durante más de 30 minutos. Según lo solicitado, mi número de placa es ABC2021. \"\n",
    "                 \"Como dije por teléfono, el accidente fue la otra falla de la SUV por hacer un giro brusco y \"\n",
    "                 \"golpear mi auto en el lado derecho del pasajero. Afortunadamente no me lastimé, pero el daño \"\n",
    "                 \"al auto es sustancial. Le solicito que procese el reclamo con urgencia y me dé un vehículo \"\n",
    "                 \"solitario mientras dure la reparación. Mi teléfono móvil es 55-999-5555 si necesita \"\n",
    "                 \"comunicarse conmigo. Gracias.\")\n",
    "print(claim_spanish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = client.detect_language(documents = [claim_spanish], country_hint = 'us')[0]\n",
    "    print(\"Language:\", response.primary_language.name)\n",
    "    print(\"Confidence Score:\", response.primary_language.confidence_score)\n",
    "    save_output(response, 'language_detection_results')\n",
    "except Exception as err:\n",
    "    print(\"Encountered exception. {}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's detect the language of the original claim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = None\n",
    "try:\n",
    "    response = client.detect_language(documents = [claim], country_hint = 'us')[0]\n",
    "    language = response.primary_language.name\n",
    "    print(\"Language:\", response.primary_language.name)\n",
    "    print(\"Confidence Score:\", response.primary_language.confidence_score)\n",
    "    save_output(response, 'language_detection_results')\n",
    "except Exception as err:\n",
    "    print(\"Encountered exception. {}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personally Identifiable Information (PII) Detection\n",
    "\n",
    "The PII Detection extracts personal information from an input text and gives you the option of masking it. Run the cell below to identify PII in the claims text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.textanalytics import PiiEntityCategory\n",
    "redacted_claim = None\n",
    "response = client.recognize_pii_entities([claim], language=\"en\", \n",
    "                                         categories_filter=[PiiEntityCategory.PERSON, \n",
    "                                                            PiiEntityCategory.PHONE_NUMBER])\n",
    "result = [doc for doc in response if not doc.is_error]\n",
    "for doc in result:\n",
    "    redacted_claim = doc.redacted_text\n",
    "    print(\"Redacted Text: {}\".format(redacted_claim))\n",
    "    for entity in doc.entities:\n",
    "        print(\"Entity: {}\".format(entity.text))\n",
    "        print(\"\\tCategory: {}\".format(entity.category))\n",
    "        print(\"\\tConfidence Score: {}\".format(entity.confidence_score))\n",
    "    save_output(response, 'pii_detection_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Results in Blob Store\n",
    "\n",
    "Save the JSON responses that came from the various cognitive services to a permanent store like the blob storage for future reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been saving the JSON outputs as pickle files temporarily in a local directory. Let’s review the saved files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $output_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the `Workspace` from the saved config file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upload the files from the local directory to the default blob store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = ws.get_default_datastore()\n",
    "datastore.upload(output_location, \n",
    "                 target_path = 'cs_results', \n",
    "                 overwrite = True, \n",
    "                 show_progress = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to your resource group’s storage account, select **Containers**, and then select the default blob store **azureml-blobstore-xxx**. Next, select the folder **cs_results** to view the saved files.\n",
    "\n",
    "\n",
    "![Image showing uploaded results from the cognitive services APIs.](./images/blob_files.png 'Blobs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoking the Azure ML Deployed Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to define a method that will be used to invoke your classifier and summarizer methods deployed using Azure Machine Learning service to Azure Container Instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def invoke_service(ml_service_key, ml_service_scoring_endpoint, ml_service_input):\n",
    "    headers   = {\"Authorization\": \"Bearer \" + ml_service_key}\n",
    "    response  = requests.post(ml_service_scoring_endpoint, headers=headers, json=ml_service_input)\n",
    "    result = response.json()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the classifier invocation with the key and endpoint URI (**classifier_service_scoring_endpoint**) as appropriate to your deployed instance:\n",
    "\n",
    "> This is the scoring endpoint URI you copied from the notebook named `04 Deploy Classifier Web Service.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_service_key = \"\" #leave this value empty if the service does not have authentication enabled\n",
    "#\"<your_classifier_scoring_url>\"\n",
    "classifier_service_scoring_endpoint = '...'\n",
    "classifier_service_input = [claim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke the classifier and observe the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_result = invoke_service(classifier_service_key, \n",
    "                                   classifier_service_scoring_endpoint, classifier_service_input)\n",
    "classifier_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret the classifier result\n",
    "classification = 'Auto Insurance Claim' if classifier_result == 1 else 'Home Insurance Claim' \n",
    "classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, configure the key and scoring endpoint URI (**summarizer_service_scoring_endpoint**) as appropriate to your summarizer service:\n",
    "\n",
    "> This is the scoring endpoint URI you copied from the notebook named `02 Deploy Summarizer Web Service.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_service_key = \"\" #leave this value empty if the service does not have authentication enabled\n",
    "#\"<your_summarizer_service_url>\"\n",
    "summarizer_service_scoring_endpoint = '...'\n",
    "summarizer_service_input = claim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke the summarizer service and observe the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_result = invoke_service(summarizer_service_key, summarizer_service_scoring_endpoint, \n",
    "                                   summarizer_service_input)\n",
    "formatted_summary =  summarizer_result[0].replace(\"\\\\n\", \" \").strip() if len(summarizer_result) > 0 else \"N/A\"\n",
    "print(formatted_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing the Results\n",
    "\n",
    "In this final task, you pull together all of the pieces to display the results of your AI based processing.\n",
    "\n",
    "Run the following cell and examine the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "displayTemplate = \"\"\"\n",
    "<div><h1>Claim Summary</h1></div>\n",
    "<div>&nbsp;</div>\n",
    "<div>Claim Type: <b>{}</b></div>\n",
    "<div>Language: {}</div>\n",
    "<div>Overall Sentiment: {}</div>\n",
    "<div>Overall Positive Sentiment Score: {}</div>\n",
    "<div>Overall Negative Sentiment Score: {}</div>\n",
    "<div>&nbsp;</div>\n",
    "<div>Key Phrases:</div>\n",
    "<div><b>{}</b></div>\n",
    "<div><b>{}</b></div>\n",
    "<div><b>{}</b></div>\n",
    "<div><b>{}</b></div>\n",
    "<div><b>{}</b></div>\n",
    "<div>&nbsp;</div>\n",
    "<div>Key Opinion:</div>\n",
    "<div><pre>{}</pre></div>\n",
    "<div>Target: <b>{}</b> Sentiment: <b>{}</b></div>\n",
    "<div>Assessment: <b>{}</b> Sentiment: <b>{}</b></div>\n",
    "<div>&nbsp;</div>\n",
    "<div>Claim Summary:</div>\n",
    "<div><pre>{}</pre></div>\n",
    "<div>&nbsp;</div>\n",
    "<div>Redacted Claim:</div>\n",
    "<div>{}</div>\n",
    "\"\"\"\n",
    "displayTemplate = displayTemplate.format(classification, \n",
    "                                         language, \n",
    "                                         overall_sentiment, \n",
    "                                         overall_positive_score, \n",
    "                                         overall_negative_score,  \n",
    "                                         key_phrases[0],\n",
    "                                         key_phrases[1],\n",
    "                                         key_phrases[2],\n",
    "                                         key_phrases[3],\n",
    "                                         key_phrases[4],\n",
    "                                         opinions[0]['Sentence'],\n",
    "                                         opinions[0]['target'],\n",
    "                                         opinions[0]['target_sentiment'], \n",
    "                                         opinions[0]['assessments'][0]['assessment'],\n",
    "                                         opinions[0]['assessments'][0]['assessment_sentiment'],\n",
    "                                         formatted_summary, \n",
    "                                         redacted_claim\n",
    "                                        )\n",
    "display(HTML(displayTemplate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
